{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe44cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import fnmatch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from  numpy import exp,absolute\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, TensorDataset, Subset\n",
    "import pandas as pd\n",
    "from torchmetrics.functional.classification import multiclass_confusion_matrix as mcm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score ,recall_score \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf3b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "dataset_path = './data/multiclass_dataset/'\n",
    "\n",
    "bs = 64\n",
    "test_size = 0.15  # Test set size (20%)\n",
    "val_size = 0.2   # Validation set size (25%)\n",
    "num_epoch = 60\n",
    "patience = 20\n",
    "classes = sorted(os.listdir(Path(dataset_path) / 'data')) #arranged in order of their placement in the folder\n",
    "num_classes = len(classes)\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c771cd8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_denoise(image):\n",
    "    # Denoising transformation (replace with your denoising algorithm)\n",
    "    # Example: Apply Gaussian blur with a kernel size of 3\n",
    "    denoised_image = transforms.functional.gaussian_blur(image, kernel_size=3,sigma=1.5)\n",
    "    return denoised_image\n",
    "\n",
    "def transform_enhance(image):\n",
    "    # Image enhancement transformation (replace with your enhancement algorithm)\n",
    "    # Example: Apply contrast enhancement\n",
    "    enhanced_image = transforms.functional.adjust_contrast(image, contrast_factor=1.5)\n",
    "    return enhanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338e5b0e-59b4-4bdc-96dc-772b585bb303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a78336-04ee-4ce6-b01b-cce532f30279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(dataset, size=2998):\n",
    "    # Get the labels for the dataset\n",
    "    labels = np.asarray(dataset.dataset.imgs)[:, 1]\n",
    "\n",
    "    # Create a new subset of the dataset\n",
    "    indices = []\n",
    "    new_class_counts = defaultdict(int)\n",
    "    for i in range(len(dataset)):\n",
    "        label = labels[i]\n",
    "        if new_class_counts[label] < size:\n",
    "            indices.append(i)\n",
    "            new_class_counts[label] += 1\n",
    "\n",
    "    return Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40607c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path,val_split,test_split):\n",
    "    transform_train = transforms.Compose([\n",
    "                                        transforms.Resize((256, 256)),\n",
    "                                        transforms.Lambda(lambda x: transform_denoise(x)),\n",
    "                                        transforms.Lambda(lambda x: transform_enhance(x)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.RandomRotation(degrees=10),\n",
    "                                        transforms.RandomCrop(size=256),\n",
    "                                        transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "    transform_test = transforms.Compose([\n",
    "                                        transforms.Resize((256, 256)),\n",
    "                                        transforms.Lambda(lambda x: transform_denoise(x)),\n",
    "                                        transforms.Lambda(lambda x: transform_enhance(x)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(path)    \n",
    "    trainset,valset,testset = stratified(dataset)\n",
    "\n",
    "    trainset = DatasetFromSubset(trainset, transform=transform_train)\n",
    "    valset = DatasetFromSubset(valset, transform=transform_test)\n",
    "    testset = DatasetFromSubset(testset, transform=transform_test)\n",
    "    \n",
    "    print(\"train :\",len(trainset),\"val :\",len(valset),\"test :\",len(testset))\n",
    "    \n",
    "    return trainset,valset,testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40e7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_indices(indices, images, name):\n",
    "    file_list = np.asarray(images)[indices]\n",
    "\n",
    "    with open(Path(dataset_path) / (name + '.txt'), 'w') as f:\n",
    "        f.writelines(file_list)\n",
    "\n",
    "\n",
    "def stratified(dataset):\n",
    "    # Get the labels and targets from the dataset\n",
    "    labels = np.asarray(dataset.imgs)[:, 1]\n",
    "\n",
    "    stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    train_val_indices, test_indices = next(stratified_split.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "    train_val_dataset = torch.utils.data.Subset(dataset, train_val_indices)\n",
    "    testset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    # write down the splits\n",
    "    imgs = [img[0] + '\\n' for img in dataset.imgs]\n",
    "    write_indices(train_val_indices, imgs, \"train_images\")\n",
    "    write_indices(test_indices, imgs, \"test_images\")\n",
    "    with open(Path(dataset_path) / \"all_images.txt\", \"w\") as f:\n",
    "        f.writelines(imgs)\n",
    "\n",
    "    # balance the train set\n",
    "    train_val_dataset = subsample(train_val_dataset)\n",
    "    \n",
    "    # Further split the train-val dataset into train and validation sets\n",
    "    stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=42)\n",
    "    train_indices, val_indices = next(stratified_split.split(train_val_dataset, labels[train_val_indices][train_val_dataset.indices]))\n",
    "\n",
    "    trainset = torch.utils.data.Subset(train_val_dataset, train_indices)\n",
    "    valset = torch.utils.data.Subset(train_val_dataset, val_indices)\n",
    "\n",
    "    return trainset,valset,testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83bb72f8-7200-4a9e-ba8a-d1644ce63e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset, valset, testset = get_dataset(Path(dataset_path) / 'data', val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47ff9f2-a618-42e7-9aa1-6494c3770eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(tensor):\n",
    "    probabilities = torch.softmax(tensor, dim=1)\n",
    "    return -torch.sum(probabilities * torch.log2(probabilities + 1e-10), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54100a7-426f-4c7e-8a85-b67245ec923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainset,valset, model, criterion, optimizer, num_epochs, bs):\n",
    "    dataloaders_strong = {\n",
    "        'train': data.DataLoader(trainset, batch_size=bs, shuffle=True),\n",
    "        'val': data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    }\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, epochs=num_epoch, steps_per_epoch=len(dataloaders_strong['train']), max_lr=0.1)\n",
    "    dataset_sizes_strong = {'train': len(trainset), 'val': len(valset)}\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    epochs_without_improvement = 0  # Reset the counter since there is improvement\n",
    "\n",
    "    # Lists to store entropy values for each epoch\n",
    "    entropy_values_train = []\n",
    "    entropy_values_val = []\n",
    "    # Lists to store loss of each epoch\n",
    "    E_loss_train = []\n",
    "    E_loss_val = []\n",
    "    E_accuracy_train = []\n",
    "    E_accuracy_val = []\n",
    "    # Lists to store balanced accuracy for training and validation phases\n",
    "    balanced_acc_train = []\n",
    "    balanced_acc_val = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        c = 0\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            all_labels = []\n",
    "            all_preds = []\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            epoch_entropy = 0.0  # Variable to store epoch entropy\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders_strong[phase], \"Running \" + phase):\n",
    "                inputs = inputs.to(device)                \n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Calculate balanced accuracy only if all unique predicted classes are present in true labels\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                        balanced_acc = balanced_accuracy_score(labels.cpu(), preds.cpu())\n",
    "                        \n",
    "                    all_labels.extend(labels.cpu().tolist())\n",
    "                    all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "                    # Backpropagation and optimization\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()   \n",
    "                        scheduler.step()               \n",
    "                    \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                # Calculate entropy for each batch and accumulate for epoch entropy\n",
    "                e = entropy(outputs)\n",
    "                epoch_entropy += torch.sum(e)\n",
    "\n",
    "            \n",
    "            if phase == 'train':\n",
    "                epoch_loss = running_loss / dataset_sizes_strong[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes_strong[phase]\n",
    "                epoch_entropy /= dataset_sizes_strong[phase] # Calculate average epoch entropy\n",
    "            else:\n",
    "                epoch_loss = running_loss / (dataset_sizes_strong[phase]-c)\n",
    "                epoch_acc = running_corrects.double() / (dataset_sizes_strong[phase]-c)\n",
    "                epoch_entropy /= (dataset_sizes_strong[phase]-c) # Calculate average epoch entropy\n",
    "\n",
    "                \n",
    "                # print('Number of skipped:', c)\n",
    "                # print()\n",
    "            \n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print('{} Epoch Entropy: {:.4f}'.format(phase, epoch_entropy.item()))\n",
    "            print('{} Balanced Accuracy: {:.4f}'.format(phase, balanced_acc))\n",
    "            print()\n",
    "\n",
    "            if phase == 'train':\n",
    "                entropy_values_train.append(epoch_entropy.item())\n",
    "                E_loss_train.append(epoch_loss)\n",
    "                balanced_acc_train.append(balanced_acc)  # Append balanced accuracy for training\n",
    "                E_accuracy_train.append(epoch_acc)\n",
    "            else:\n",
    "                entropy_values_val.append(epoch_entropy.item())\n",
    "                E_loss_val.append(epoch_loss)\n",
    "                balanced_acc_val.append(balanced_acc)  # Append balanced accuracy for validation\n",
    "                E_accuracy_val.append(epoch_acc)\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            # cm = confusion_matrix(all_labels, all_preds)\n",
    "            # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "            # disp.plot()\n",
    "            # plt.figure(figsize=(8, 6))\n",
    "            # plt.show()\n",
    "            \n",
    "            # Deep copy the model if the validation accuracy improves\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_epoch_val = epoch\n",
    "                \n",
    "                \n",
    "            # Early stopping criteria\n",
    "            if phase == 'val' and epoch > 0:\n",
    "                if epoch_loss >= E_loss_val[-1]:\n",
    "                    epochs_without_improvement += 1\n",
    "                else:\n",
    "                    epochs_without_improvement = 0\n",
    "\n",
    "                if epochs_without_improvement >= patience:\n",
    "                    print('Early stopping due to no improvement in validation loss.')\n",
    "                    return (\n",
    "                        model,\n",
    "                        entropy_values_train,\n",
    "                        entropy_values_val,\n",
    "                        E_loss_train,\n",
    "                        E_loss_val,\n",
    "                        balanced_acc_train,\n",
    "                        balanced_acc_val\n",
    "                    ) \n",
    "                \n",
    "            # Overfitting criteria\n",
    "            if phase == 'train' and epoch_loss <= E_loss_train[-1]:\n",
    "                epochs_without_improvement += 1\n",
    "                if epochs_without_improvement >= patience:\n",
    "                    print('Training stopped due to overfitting.')\n",
    "                    return (\n",
    "                        model,\n",
    "                        entropy_values_train,\n",
    "                        entropy_values_val,\n",
    "                        E_loss_train,\n",
    "                        E_loss_val,\n",
    "                        balanced_acc_train,\n",
    "                        balanced_acc_val\n",
    "                    )\n",
    "            else:\n",
    "                epochs_without_improvement = 0\n",
    "                \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best Val Acc. was achieved at epoch', best_epoch_val)\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        entropy_values_train,\n",
    "        entropy_values_val,\n",
    "        E_loss_train,\n",
    "        E_loss_val,\n",
    "        balanced_acc_train,\n",
    "        balanced_acc_val,\n",
    "        E_accuracy_train,\n",
    "        E_accuracy_val\n",
    "    )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66509907-64e6-4e31-a287-5c6dd90837d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, testset, confidence_threshold):\n",
    "    running_corrects = 0\n",
    "    testloader = data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    c = 0\n",
    "    confidence_scores_distribution = []\n",
    "    model.eval()\n",
    "    \n",
    "    for inputs, labels in tqdm(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Calculate confidence score for each sample in the batch\n",
    "            confidence_scores = 1 - entropy(outputs)\n",
    "            if confidence_threshold == 0:\n",
    "                confidence_scores_distribution.append(confidence_scores.cpu().numpy())\n",
    "\n",
    "            # Skip predictions if confidence score is greater than the threshold\n",
    "            skip_mask = confidence_scores >= confidence_threshold\n",
    "                    \n",
    "            c += len(skip_mask) - skip_mask.sum().item()\n",
    "            inputs = inputs[skip_mask]\n",
    "            labels = labels[skip_mask]\n",
    "            preds = preds[skip_mask]\n",
    "                \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "    test_accuracy = running_corrects / (len(testset)-c)\n",
    "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(\"The Test Accuracy:\", test_accuracy)\n",
    "    print(\"The Test Balanced Accuracy:\", balanced_acc)\n",
    "    print(\"Skipped Inputs:\", c)\n",
    "    if confidence_threshold == 0:\n",
    "        confidence_scores_distribution = np.concatenate(confidence_scores_distribution)\n",
    "        # plt.hist(confidence_scores_distribution, bins=100)\n",
    "        # plt.gca().set(title='Confidence Histogram', ylabel='Occurrences');\n",
    "        # plt.show()\n",
    "        \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes )\n",
    "    disp.plot()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.show()\n",
    "    return balanced_acc, 1 - c / len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d8553c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, requires_grad=True):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c7968e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 256\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        # Resnet50\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, requires_grad=True)\n",
    "        model_ft.fc = nn.Linear(model_ft.fc.in_features, num_classes)\n",
    "        \n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        # VGG16_bn\n",
    "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, requires_grad=True)\n",
    "        model_ft.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "    elif model_name == \"googlenet\":\n",
    "        # GoogLeNet\n",
    "        model_ft = torchvision.models.googlenet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, requires_grad=True)\n",
    "        model_ft.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        # Densenet\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, requires_grad=True)\n",
    "        model_ft.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ed233be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "584f8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def plot_distribution_by_class(labels, classes):\n",
    "\n",
    "    labels, count = np.unique(np.asarray(labels), return_counts=True)\n",
    "    labels = np.asarray([classes[int(i)] for i in labels])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # Set the size of the figure\n",
    "\n",
    "    x = np.arange(len(labels))  # Generate an array of class indices\n",
    "    plt.bar(x, count)\n",
    "    plt.xticks(x, labels, rotation=45, ha='right')  # Set custom x-axis tick positions and labels\n",
    "    plt.xlabel(\"Classes\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Class Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db923780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 19187 val : 4797 test : 29724\n"
     ]
    }
   ],
   "source": [
    "# Separate the train, val, and test sets\n",
    "trainset,valset,testset = get_dataset(Path(dataset_path) / 'data', val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5997bcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_ = trainset.subset.dataset.dataset.dataset\n",
    "labels = np.asarray(data_.imgs)[trainset.subset.dataset.dataset.indices]\n",
    "labels = labels[trainset.subset.dataset.indices]\n",
    "labels = labels[trainset.subset.indices, 1]\n",
    "\n",
    "plot_distribution_by_class(labels, data_.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0723c22-be40-4ddd-b86e-0488f4ed0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14c50fe9-b336-4f34-9de3-fa5c8c4c5d95",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model_name(model_name):\n",
    "    print(model_name)\n",
    "    # Initialize the model\n",
    "    model, input_size = initialize_model(model_name, num_classes, use_pretrained=True)\n",
    "    \n",
    "    \n",
    "    # Send model to GPU, if available\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer = optim.SGD(model.parameters())\n",
    "    model, entropy_values_train, entropy_values_val, E_loss_train, E_loss_val, balanced_acc_train, balanced_acc_val,E_accuracy_train,E_accuracy_val = train_model(\n",
    "        trainset,valset,model, criterion, optimizer, num_epoch, bs)\n",
    "\n",
    "        \n",
    "    # Plot entropy values\n",
    "    plt.figure()\n",
    "    plt.plot(entropy_values_train, label='Train')\n",
    "    plt.plot(entropy_values_val, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Entropy')\n",
    "    plt.title('Entropy Trend')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot loss values\n",
    "    plt.figure()\n",
    "    plt.plot(E_loss_train, label='Train')\n",
    "    plt.plot(E_loss_val, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Trend')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot balanced loss values\n",
    "    plt.figure()\n",
    "    plt.plot(balanced_acc_train, label='Train')\n",
    "    plt.plot(balanced_acc_val, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Balanced Accuracy')\n",
    "    plt.title('Balanced Accuracy Trend')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "467e3b95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/federico/omr/__pypackages__/3.9/lib/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/federico/omr/__pypackages__/3.9/lib/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/59\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   0%|                                                                                                                                                                                                    | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   0%|                                                                                                                                                                                           | 1/300 [00:01<06:34,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   1%|                                                                                                                                                                                          | 2/300 [00:02<05:06,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   1%|                                                                                                                                                                                          | 3/300 [00:02<04:35,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   1%|                                                                                                                                                                                         | 4/300 [00:03<04:15,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   2%|                                                                                                                                                                                        | 5/300 [00:04<04:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   2%|                                                                                                                                                                                        | 6/300 [00:05<04:01,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   2%|                                                                                                                                                                                       | 7/300 [00:06<03:57,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   3%|                                                                                                                                                                                       | 8/300 [00:06<03:47,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   3%|                                                                                                                                                                                      | 9/300 [00:07<03:40,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   3%|                                                                                                                                                                                    | 10/300 [00:08<03:41,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   4%|                                                                                                                                                                                    | 11/300 [00:09<03:39,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   4%|                                                                                                                                                                                   | 12/300 [00:09<03:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   4%|                                                                                                                                                                                   | 13/300 [00:10<03:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   5%|                                                                                                                                                                                  | 14/300 [00:11<03:32,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   5%|                                                                                                                                                                                 | 15/300 [00:12<03:35,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   5%|                                                                                                                                                                                 | 16/300 [00:12<03:38,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   6%|                                                                                                                                                                                | 17/300 [00:13<03:35,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   6%|                                                                                                                                                                               | 18/300 [00:14<03:35,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   6%|                                                                                                                                                                               | 19/300 [00:15<03:35,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   7%|                                                                                                                                                                              | 20/300 [00:15<03:34,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   7%|                                                                                                                                                                              | 21/300 [00:16<03:38,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   7%|                                                                                                                                                                             | 22/300 [00:17<03:32,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   8%|                                                                                                                                                                            | 23/300 [00:18<03:34,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   8%|                                                                                                                                                                            | 24/300 [00:19<03:34,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   8%|                                                                                                                                                                           | 25/300 [00:19<03:32,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   9%|                                                                                                                                                                          | 26/300 [00:20<03:31,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   9%|                                                                                                                                                                          | 27/300 [00:21<03:32,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:   9%|                                                                                                                                                                         | 28/300 [00:22<03:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:  10%|                                                                                                                                                                         | 29/300 [00:22<03:32,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running train:  10%|                                                                                                                                                                        | 30/300 [00:23<03:34,  1.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2092149/1405983264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'densenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2092149/3401393029.py\u001b[0m in \u001b[0;36mtrain_model_name\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Observe that all parameters are being optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     model, entropy_values_train, entropy_values_val, E_loss_train, E_loss_val, balanced_acc_train, balanced_acc_val,E_accuracy_train,E_accuracy_val = train_model(\n\u001b[0m\u001b[1;32m     15\u001b[0m         trainset,valset,model, criterion, optimizer, num_epoch, bs)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2092149/2524909372.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainset, valset, model, criterion, optimizer, num_epochs, bs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders_strong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Running \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2092149/4058630576.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2092149/3361463272.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransform_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransform_enhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomRotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2092149/1089802598.py\u001b[0m in \u001b[0;36mtransform_enhance\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Image enhancement transformation (replace with your enhancement algorithm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Example: Apply contrast enhancement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0menhanced_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0menhanced_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36madjust_contrast\u001b[0;34m(img, contrast_factor)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36madjust_contrast\u001b[0;34m(img, contrast_factor)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0menhancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrast_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/PIL/ImageEnhance.py\u001b[0m in \u001b[0;36menhance\u001b[0;34m(self, factor)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \"\"\"\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegenerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/omr/__pypackages__/3.9/lib/PIL/Image.py\u001b[0m in \u001b[0;36mblend\u001b[0;34m(im1, im2, alpha)\u001b[0m\n\u001b[1;32m   3379\u001b[0m     \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3380\u001b[0m     \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3381\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "model_list.append(train_model_name('densenet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28401d10-ca15-4ba4-b5e4-0b26fd48b6df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_list.append(train_model_name('resnet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc590dbd-42f2-4cfb-a367-4baf0eda6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list.append(train_model_name('googlenet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c31745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models to file\n",
    "for i, model in enumerate(model_list):\n",
    "\n",
    "    # Define the file path to save the model\n",
    "    model_file1 = f'./model_state_multiclass_{i}.pt'\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), model_file1)\n",
    "    \n",
    "    model_file2 = f'./model_entire_multiclass_{i}.pt'\n",
    "    \n",
    "    # Save the entire model\n",
    "    torch.save(model, model_file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422cbe8-d193-4ab9-8a94-5fa9161b446b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confidence_thresholds = [0., .25, .5, .75, .9]\n",
    "model_names = {\n",
    "    0: \"DenseNet\",\n",
    "    1: \"ResNet\",\n",
    "    2: \"GoogleNet\"\n",
    "}\n",
    "\n",
    "confidence_results = [[] for _ in model_list]\n",
    "confidence_size = [[] for _ in model_list]\n",
    "for i, model in enumerate(model_list):\n",
    "    # # Load the model from file model\n",
    "    # model = torch.load(f'./model_entire_multiclass_{i}.pt')\n",
    "    \n",
    "    # # Load the state dictionary from the model_state file\n",
    "    # state_dict = torch.load(f'./model_state_multiclass_{i}.pt')\n",
    "    \n",
    "    # # Load the state dictionary into the model\n",
    "    # model.load_state_dict(state_dict)\n",
    "    \n",
    "    for confidence_threshold in confidence_thresholds:\n",
    "        print(f\"{model_names[i]} - Confidence {int(confidence_threshold * 100)}%\")\n",
    "        result, size = test_model(model, testset, confidence_threshold)\n",
    "        confidence_results[i].append(result)\n",
    "        confidence_size[i].append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ac8ca-1dc4-4aac-bee7-4f7887b677e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting confidence scores\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.suptitle('Results by confidence thresholds')\n",
    "\n",
    "# plotting confidence\n",
    "for i, result in enumerate(confidence_results):\n",
    "    ax1.plot(confidence_thresholds, result, label=model_names[i])\n",
    "# plotting data size\n",
    "for i, size in enumerate(confidence_size):\n",
    "    ax2.plot(confidence_thresholds, size, label=model_names[i])\n",
    "\n",
    "# Set labels\n",
    "ax1.set_ylabel('Balanced Accuracy')\n",
    "# Display the legend\n",
    "ax1.legend()\n",
    "\n",
    "# Set labels\n",
    "ax2.set_xlabel('Confidence scores')\n",
    "ax2.set_ylabel('Percentage of retained dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6069569-e943-4364-9a1f-34ccecccd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_to_numpy(dataloader):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for data, label in tqdm(dataloader):\n",
    "        # Reshape the data to 1D\n",
    "        data = data.view(-1)\n",
    "        data_list.append(data.numpy())\n",
    "        label_list.append(label)\n",
    "    return np.stack(data_list), np.asarray(label_list)\n",
    "\n",
    "# Convert dataloaders to numpy arrays\n",
    "print(\"Converting validation set\")\n",
    "valset.transform = transform_train\n",
    "val_X, val_Y = dataloader_to_numpy(valset)\n",
    "print(\"Converting train set\")\n",
    "train_X, train_Y = dataloader_to_numpy(trainset)\n",
    "print(\"Converting test set\")\n",
    "test_X, test_Y = dataloader_to_numpy(testset)\n",
    "\n",
    "# Concatenate training set and validation set\n",
    "train_X = np.concatenate((train_X, val_X), axis=0)\n",
    "train_Y = np.concatenate((train_Y, val_Y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c611af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dummy prediction, i.e Random Baseline\n",
    "# Create a dummy classifier with a strategy\n",
    "dummy_clf = DummyClassifier(strategy='uniform')\n",
    "\n",
    "# Train the dummy classifier\n",
    "dummy_clf.fit(train_X, train_Y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = dummy_clf.predict(test_X)\n",
    "\n",
    "# Evaluate the accuracy of the dummy classifier\n",
    "accuracy = dummy_clf.score(test_X, test_Y)\n",
    "\n",
    "print(\"Dummy Classifier Accuracy/ Random Baseline:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddac122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using SVM\n",
    "model_svc = SVC(decision_function_shape='ovr', C=100, kernel='rbf')\n",
    "model_svc.fit(train_X, train_Y)\n",
    "pred = model_svc.predict(test_X)\n",
    "acc = accuracy_score(test_Y, pred)\n",
    "print('Accuracy for SVM: ' + str(acc))\n",
    "balanced_svm = balanced_accuracy_score(test_Y, pred)  # Calculate balanced accuracy\n",
    "print(\"Balanced Accuracy:\"+ str(balanced_svm))\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_Y, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes )\n",
    "disp.plot()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using MLP\n",
    "model_mlp = mlp(solver='lbfgs', alpha=1e-5, random_state=5, max_iter=100000)\n",
    "model_mlp.fit(train_X, train_Y)\n",
    "pred = model_mlp.predict(test_X)\n",
    "acc = accuracy_score(test_Y, pred)\n",
    "print('Accuracy for MLP: ' + str(acc))\n",
    "balanced_mlp = balanced_accuracy_score(test_Y, pred)  # Calculate balanced accuracy\n",
    "print(\"Balanced Accuracy:\"+ str(balanced_mlp))\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_Y, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes )\n",
    "disp.plot()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
