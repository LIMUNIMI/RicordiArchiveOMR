{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import krippendorff as kd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df68538-eeba-483a-bb1c-971f72446caf",
   "metadata": {},
   "source": [
    "## Let's compute the annotator agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d9264-34b9-4f22-b9af-6e301b9effaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Separating the list of lists\n",
    "\"\"\"\n",
    "def schools(path):\n",
    "    f = open(path)\n",
    "    Json_Data = json.load(f)\n",
    "    res = []\n",
    "    for key, val in Json_Data.items():\n",
    "        res.append([key] + val)\n",
    "\n",
    "    tenca1 = res[0][1:]\n",
    "    tenca2 = res[1][1:]\n",
    "    majorana_setti1 = res[2][1:]\n",
    "    alessandrini_titolivio1 = res[3][1:]\n",
    "    mariecurie_cernusco1 = res[4][1:]\n",
    "    tenca3 = res[5][1:]\n",
    "    bachelet_abbiategrasso = res[6][1:]\n",
    "    \n",
    "    return tenca1,tenca2,majorana_setti1,alessandrini_titolivio1,mariecurie_cernusco1,tenca3,bachelet_abbiategrasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385da051-d2bb-4a2a-8acb-b45b92e80634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the precdiction list of the schools set using mode\n",
    "\"\"\"\n",
    "\n",
    "def Mode(list):\n",
    "    \n",
    "    mode_list = []\n",
    "    for i in list:\n",
    "        j = st.mode(i)\n",
    "        mode_list.append(j)\n",
    "    \n",
    "    return mode_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f53d3-d874-4b42-b855-b6092b244ab5",
   "metadata": {},
   "source": [
    "## `true_annotations` computes the most common annotations for each sample (the reference annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Creating the true annotation set using mode\n",
    "\"\"\" \n",
    "def true_annotations(tenca1,tenca2,majorana_setti1,alessandrini_titolivio1,mariecurie_cernusco1,tenca3,bachelet_abbiategrasso):  \n",
    "    true_list = []\n",
    "    track = []\n",
    "    for i in range(0,500):\n",
    "        track.append(tenca1[i]+tenca2[i]+majorana_setti1[i]+alessandrini_titolivio1[i]+mariecurie_cernusco1[i]+tenca3[i]+bachelet_abbiategrasso[i])\n",
    "    \n",
    "    true_list= Mode(track) \n",
    "    \n",
    "    return true_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e96600-22e1-47ac-9d29-f0abfc562fb6",
   "metadata": {},
   "source": [
    "## `predicted_annotations` computes a reference annotation for each school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0923b-90f2-484e-813a-2d98bab7b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_annotations(tenca1,tenca2,majorana_setti1,alessandrini_titolivio1,mariecurie_cernusco1,tenca3,bachelet_abbiategrasso):\n",
    "    Tenca1 = Mode(tenca1)\n",
    "    Tenca2 = Mode(tenca2)\n",
    "    Majorana_Setti1 = Mode(majorana_setti1)\n",
    "    Alessandrini_Titolivio1 = Mode(alessandrini_titolivio1)\n",
    "    Mariecurie_Cernusco1 = Mode(mariecurie_cernusco1)\n",
    "    Tenca3 = Mode(tenca3)\n",
    "    Bachelet_Abbiategrasso = Mode(bachelet_abbiategrasso)\n",
    "\n",
    "    school_list = [Tenca1, Tenca2, Majorana_Setti1, Alessandrini_Titolivio1, Mariecurie_Cernusco1, Tenca3, Bachelet_Abbiategrasso]\n",
    "    return school_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intra_rater_agreement(bar_list, names):\n",
    "    plt.figure(figsize=(10, 8))  # smaller plot size\n",
    "    plt.bar(names, bar_list, color='black')  # plotting in black\n",
    "    plt.xlabel('School Names', fontsize=14)  # smaller font size for labels\n",
    "    plt.ylabel('Krippendorff\\'s alpha', fontsize=14)  # smaller font size for labels\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)  # rotate x-axis labels for better visibility\n",
    "    plt.yticks(fontsize=12)  # smaller font size for y-axis ticks\n",
    "    plt.tight_layout()  # adjust layout to prevent overlap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eefb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "Annonator asgreement\n",
    "\"\"\"\n",
    "def IntraRater(list_of_lists):#Intra Rater\n",
    "    min_len = min(len(L) for L in list_of_lists)\n",
    "    list_of_lists = [L[:min_len] for L in list_of_lists]\n",
    "    agreement = kd.alpha(np.array(list_of_lists).T)\n",
    "   \n",
    "    return agreement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc17870",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './__annotator.json'\n",
    "\n",
    "\"\"\"\n",
    "\"Page border\"= 0\n",
    "Erasure = 1\n",
    "Burr = 2\n",
    "\"Printed Text\" = 3\n",
    "\"Manuscript Text\" = 4\n",
    "\"Pause (full or almost)\" = 5\n",
    "\"Single note (with at least the head)\" = 6\n",
    "\"Multiple Notes (with at least the head)\" = 7\n",
    "\"Single chord (with at least heads)\" = 8\n",
    "\"Multiple chords (with at least heads)\" = 9\n",
    "\"Accidental(s) (whole or nearly so)\" = 10\n",
    "\"Key(s) (whole(s) or nearly)\" = 11\n",
    "\"Embellishment(s) (whole(s) or nearly)\" = 12\n",
    "\"More categories (with at least one musical score)\" = 14\n",
    "\"More categories (no musical scores)\" = 15\n",
    "\"Other (with at least one musical score)\" = 16\n",
    "\"Other (without musical markings)\" = 17\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "classes_relevant = [5,6,7,8,9,11,12,13,14,16]\n",
    "classes_irrelevant = [0,1,2,3,4,15,17]\n",
    "\n",
    "classes = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17']\n",
    "\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_ = schools(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1895c4-f124-40b2-a901-b20438a455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rater_agreement(schools):\n",
    "    school_list = predicted_annotations(*schools_)\n",
    "    print(\"Inter-Rater agreement: \",kd.alpha(np.array(school_list)))  #Inter-Annotator agreement assuming nominal categories\n",
    "    bar_list = [IntraRater(school) for school in schools_]\n",
    "    print(\"Intra-Rater agreement between:\", min(bar_list), \"and\", max(bar_list))\n",
    "    \n",
    "    names = ['tenca1','tenca2','majorana_setti1','alessandrini_titolivio1','mariecurie_cernusco1',\n",
    "             'tenca3','bachelet_abbiategrasso']\n",
    "    \n",
    "    plot_intra_rater_agreement(bar_list, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c49746-9dd6-44c5-9b39-22953434bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rater_agreement(schools_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848191eb-f598-4a81-8435-36df2b07fcda",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Now, let's try to merge classes to increase the annotator's agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95287c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(classes, true_list, *schools):\n",
    "    \"\"\"Computes the confusion matrix between all the annotations given and the reference annotations\"\"\"\n",
    "    #Visualize actual cnfusion matrix\n",
    "    num_classes = len(classes)\n",
    "    C_M = pd.DataFrame(np.zeros((num_classes,num_classes), dtype = int), \n",
    "                       index = classes, columns = classes)\n",
    "    for school in schools:\n",
    "        for i, sample in enumerate(school):\n",
    "            for p_label in sample:\n",
    "                t_label = true_list[i]\n",
    "                C_M.loc[str(t_label), str(p_label)] += 1\n",
    "\n",
    "    C_M_Normalized = C_M.astype('float') / C_M.max(axis=1).to_numpy()[:, np.newaxis]\n",
    "    C_M_Normalized[np.isnan(C_M_Normalized)] = 0\n",
    "    C_M_Normalized = np.round(C_M_Normalized, 3)\n",
    "    \n",
    "    return C_M_Normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8fdfa-76ed-406b-9eef-060ebb9ea281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(C_M):\n",
    "    def plot_(C_M):\n",
    "        \n",
    "        fig = plt.figure(figsize=(30, 20))\n",
    "        ax = plt.subplot()\n",
    "        sn.heatmap(C_M, annot=True, ax = ax, fmt = 'g')\n",
    "        ax.set_xlabel('Predicted Annotations', fontsize=40)\n",
    "        ax.xaxis.set_label_position('bottom')\n",
    "\n",
    "        ax.set_ylabel('Actual Annotations', fontsize=40)\n",
    "\n",
    "        plt.title('Refined Confusion Matrix', fontsize=60)\n",
    "        plt.show()\n",
    "\n",
    "    print(C_M)\n",
    "    plot_(C_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107f7bb-dd86-4b50-94d1-5e135fca97ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_list = true_annotations(*schools_)\n",
    "CM = confusion_matrix(classes, true_list, *schools_)\n",
    "# plot_confusion_matrix(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c44e72-3f1a-4e2d-a87e-73b1aaadf3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_merge_classes(CM, threshold):\n",
    "    merges = []\n",
    "    \n",
    "    for i in range(CM.shape[0]):\n",
    "        for j in range(CM.shape[1]):\n",
    "            if j >= i:\n",
    "                break\n",
    "            if CM.iloc[i, j] >= threshold:\n",
    "                merges.append((i, j))\n",
    "                print(f\"Merging {i} and {j}\")\n",
    "    return merges\n",
    "\n",
    "def apply_merge_classes(merges, *schools):\n",
    "    for school in schools_:\n",
    "        for sample in school:\n",
    "            for i, annotation in enumerate(sample):\n",
    "                for m in merges:\n",
    "                    if annotation in m[1:]:\n",
    "                        sample[i] = m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d1d40-b449-4159-9b25-a6c777e8c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.5\n",
    "while True:\n",
    "    true_list = true_annotations(*schools_)\n",
    "    CM = confusion_matrix(classes, true_list, *schools_) \n",
    "    merges = find_merge_classes(CM, th)\n",
    "    if len(merges) > 0:\n",
    "        apply_merge_classes(merges, *schools_)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a459ac0-2c8e-46ab-b061-b0edcc03074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rater_agreement(schools_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ed1b9-78b0-445d-9545-72c90edf139b",
   "metadata": {},
   "source": [
    "## Now computing agreement for the binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457117d0-74bd-40e2-875e-3a51fdaa4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = (\n",
    "    classes_relevant, classes_irrelevant\n",
    ")\n",
    "apply_merge_classes(merges, *schools_)\n",
    "rater_agreement(schools_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
